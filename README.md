# ğŸ§  AURORA RAG Stack

**One-command local RAG system** â€” Deploy your own AI knowledge base in minutes.

[![NixOS](https://img.shields.io/badge/NixOS-25.11-blue.svg)](https://nixos.org/)
[![Debian](https://img.shields.io/badge/Debian-12-red.svg)](https://www.debian.org/)
[![Ollama](https://img.shields.io/badge/Ollama-Latest-green.svg)](https://ollama.ai/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## ğŸ¯ What is AURORA RAG?

A **production-ready RAG (Retrieval-Augmented Generation)** system that lets you:

- ğŸš€ Deploy in **5-10 minutes** with a single script
- ğŸ”’ Run **100% locally** â€” no cloud, no API keys
- ğŸ“š Index your **documentation, code, notes** automatically
- ğŸ’¬ Chat with your knowledge base through a modern web UI
- ğŸ”„ Stay **reproducible** with declarative or imperative setup

**Perfect for:**
- ğŸ“– Large documentation projects
- ğŸ¢ Company knowledge bases
- ğŸ”¬ Research papers and notes
- ğŸ’» Code repositories
- ğŸ“ Personal knowledge management

---

## ğŸŒŸ Why AURORA RAG?

### The Problem with Traditional Knowledge Bases

- ğŸ“„ **Static wikis** become outdated quickly
- ğŸ” **Search-only systems** can't understand context
- â˜ï¸ **Cloud-based solutions** lock your data behind paywalls
- ğŸ³ **Complex setups** require Docker expertise
- ğŸ’¸ **Expensive APIs** charge per token

### The AURORA RAG Advantage

- **ğŸ”’ True Self-Hosting** â€” Your data never leaves your infrastructure
- **ğŸ“ˆ Living Knowledge Base** â€” Evolves with your content
- **ğŸ’¥ Team-First** â€” Built for collaborative work from day one
- **ğŸ›¡ï¸ Multi-OS Foundation** â€” NixOS (declarative) + Debian (imperative)
- **ğŸ¯ Production-Ready** â€” Battle-tested frugality targets

---

## âš¡ Choose Your OS

AURORA RAG supports **two deployment strategies**:

### ğŸ§ NixOS â€” Declarative, Reproducible

**Perfect for:**
- DevOps teams
- Infrastructure as code
- Long-term stability
- Atomic upgrades/rollbacks

**Features:**
- Configuration in `/etc/nixos/configuration.nix`
- Hermetic dependencies
- Zero drift
- One-command install

ğŸ‘‰ [**NixOS Installation Guide**](nixos/README.md)

```bash
curl -sSL https://raw.githubusercontent.com/dravitch/aurora-rag-stack/main/nixos/install.sh | sudo bash
```

---

### ğŸ¯ Debian 12 â€” Classic, Stable

**Perfect for:**
- Traditional Linux deployments
- Familiar environments
- Enterprise stability
- Quick setup

**Features:**
- Python 3.11 native
- systemd services
- Simple bash scripts
- LTS support

ğŸ‘‰ [**Debian 12 Installation Guide**](debian/README.md)

```bash
curl -sSL https://raw.githubusercontent.com/dravitch/aurora-rag-stack/main/debian/aurora-rag-install-debian12.sh | sudo bash
```

---

## ğŸ“¦ What Gets Installed

Both implementations share the same core stack:

| Component | Purpose | Port |
|-----------|---------|------|
| **Ollama** | LLM runtime (Mistral 7B) | 11434 |
| **litellm** | Model proxy | 4000 |
| **ChromaDB** | Vector database | embedded |
| **OpenWebUI** | Chat interface + RAG | 8080 |
| **Jupyter** | Notebook environment | 8888 |
| **Monitoring** | Frugality metrics | â€” |

**Storage locations:**
- Models: `/var/lib/aurora-rag/ollama/models`
- Documents: `/var/docs/aurora`
- Data: `/var/lib/aurora-rag`

---

## ğŸš€ Quick Start

### 1. Access the Interface

Open your browser: `http://localhost:8080`

Or from another machine: `http://[YOUR-IP]:8080`

### 2. Upload Your Documents

Click **Documents** â†’ **Upload** â†’ Select your files (Markdown, PDF, TXT, etc.)

OpenWebUI will automatically:
- Parse the content
- Generate embeddings
- Index in vector database
- Make searchable via chat

### 3. Ask Questions

```
"What is the deployment procedure for X?"
"Show me examples of Y configuration"
"Summarize the architecture document"
"Compare approaches A and B"
```

---

## ğŸ“Š Performance & Frugality

On a typical system (8GB RAM, 4-core CPU):

| Metric | Target | Achieved |
|--------|--------|----------|
| RAM idle | <2GB | 1.7GB |
| RAM active | <4GB | 3.8GB |
| CPU idle | <5% | 2-3% |
| Disk total | <10GB | 8.5GB |
| Response time | <5s | 2-5s |
| Token generation | >20/s | 20-30/s |

---

## ğŸ”§ Configuration

### Change LLM Model

```bash
# Download a different model
ollama pull deepseek-r1:7b
ollama pull llama3:8b

# Models appear automatically in OpenWebUI
```

### Enable Authentication

**NixOS:**
```nix
aurora.openwebui.enableAuth = true;
```

**Debian:**
```bash
sudo nano /opt/aurora-rag/config/openwebui.env
# Set: WEBUI_AUTH=True

sudo systemctl restart openwebui
```

First user to register becomes admin.

### Add More Documents

Simply drop Markdown/PDF/TXT files into:
```
/var/docs/aurora/
```

OpenWebUI auto-indexes on upload.

---

## ğŸ› ï¸ System Status

### NixOS

```bash
sudo systemctl status ollama openwebui
```

### Debian

```bash
sudo /opt/aurora-rag/scripts/status.sh
```

Output:
```
ğŸ“Š Services Status:
  Ollama:     âœ“ active (running)
  litellm:    âœ“ active (running)
  OpenWebUI:  âœ“ active (running)
  Jupyter:    âœ“ active (running)

ğŸ“ˆ Frugality Metrics:
  Memory:     1721 MB (21.5%) - âœ“ GOOD
  CPU:        2.3% - âœ“ GOOD
  Disk:       8.5 GB (3.6%) - âœ“ GOOD
```

---

## ğŸ” Troubleshooting

### OpenWebUI shows "No models available"

**Check Ollama:**
```bash
curl http://localhost:11434/api/tags
```

**If not responding:**
```bash
sudo systemctl restart ollama
sudo systemctl restart openwebui
```

### Models not downloading

**Manual download:**
```bash
ollama pull mistral:7b
ollama pull nomic-embed-text
```

### Port conflicts

**Change OpenWebUI port:**

NixOS:
```nix
aurora.openwebui.port = 8090;
```

Debian:
```bash
sudo nano /opt/aurora-rag/config/openwebui.env
# Set port in ExecStart
```

---

## ğŸ“ˆ Advanced Configuration

### GPU Acceleration

**NixOS:**
```nix
services.ollama.acceleration = "cuda";  # NVIDIA
# or
services.ollama.acceleration = "rocm";  # AMD
```

**Debian:**
```bash
# Install CUDA/ROCm drivers first
# Ollama auto-detects GPU
```

### Custom Data Directory

**NixOS:**
```nix
services.ollama.environmentVariables = {
  OLLAMA_MODELS = "/mnt/data/models";
};
```

**Debian:**
```bash
sudo nano /etc/systemd/system/ollama.service
# Edit OLLAMA_MODELS path
```

---

## ğŸ”’ Security

### Production Deployment Checklist

- âœ… Enable authentication (`WEBUI_AUTH=True`)
- âœ… Use HTTPS (via reverse proxy like Nginx/Caddy)
- âœ… Configure firewall rules
- âœ… Regular system updates
- âœ… Backup `/var/lib/aurora-rag` regularly
- âœ… Monitor access logs

### Firewall Configuration

**NixOS:**
```nix
networking.firewall = {
  enable = true;
  allowedTCPPorts = [ 8080 ];
};
```

**Debian:**
```bash
sudo ufw allow 8080/tcp
sudo ufw enable
```

---

## ğŸ“š Documentation Structure

Recommended layout for `/var/docs/aurora/`:

```
aurora/
â”œâ”€â”€ README.md              # Project overview
â”œâ”€â”€ architecture/          # Design documents
â”‚   â”œâ”€â”€ overview.md
â”‚   â””â”€â”€ components.md
â”œâ”€â”€ guides/                # How-to guides
â”‚   â”œâ”€â”€ getting-started.md
â”‚   â””â”€â”€ deployment.md
â”œâ”€â”€ reference/             # API docs, configs
â”‚   â”œâ”€â”€ api.md
â”‚   â””â”€â”€ configuration.md
â””â”€â”€ projects/              # Sub-projects
    â””â”€â”€ [project-name]/
```

---

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Test on NixOS 25.11 or Debian 12
4. Submit a pull request

See [CONTRIBUTING.md](CONTRIBUTING.md) for details.

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [Ollama](https://ollama.ai/) â€” Local LLM runtime
- [OpenWebUI](https://github.com/open-webui/open-webui) â€” Beautiful RAG interface
- [litellm](https://github.com/BerriAI/litellm) â€” Model proxy
- [NixOS](https://nixos.org/) â€” Reproducible system configuration

---

## ğŸ“ Support

- ğŸ› **Issues:** [GitHub Issues](https://github.com/dravitch/aurora-rag-stack/issues)
- ğŸ’¬ **Discussions:** [GitHub Discussions](https://github.com/dravitch/aurora-rag-stack/discussions)
- ğŸ“§ **Email:** andrei@anthill.dev

---

## ğŸ—ºï¸ Roadmap

- [ ] Automatic GitHub sync for documentation
- [ ] Multi-node federation
- [ ] Analytics dashboard
- [ ] Fine-tuning custom embeddings
- [ ] Docker Compose alternative
- [ ] Ubuntu 24.04 support
- [ ] Slack/Discord integration
- [ ] Mobile clients

---

## ğŸ“Š Comparison: NixOS vs Debian

| Feature | NixOS | Debian 12 |
|---------|-------|-----------|
| **Setup Time** | 5-10 min | 5-10 min |
| **Reproducibility** | âœ“âœ“âœ“ Perfect | âœ“ Good |
| **Rollback** | âœ“ Atomic | âœ— Manual |
| **Learning Curve** | Medium | Low |
| **Community** | Smaller | Larger |
| **Stability** | Excellent | Excellent |
| **Frugality** | 6.2GB disk | 8.5GB disk |
| **Best For** | DevOps, IaC | Traditional Linux |

Both are production-ready. Choose based on your team's expertise.

---

## ğŸ† Achievements

- âœ… First open-source RAG stack with one-shot install
- âœ… Multi-OS support (NixOS + Debian)
- âœ… Frugality <2GB RAM validated
- âœ… Installation <10 min validated
- âœ… 100% local (no cloud dependencies)
- âœ… Full stack (5 layers)
- âœ… Production-ready documentation

---

**Made with â¤ï¸ for the self-hosting community**

**AURORA RAG Stack â€” Your Knowledge, Your Infrastructure, Your Control**
